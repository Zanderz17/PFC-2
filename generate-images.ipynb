{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./matrices_por_dia'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "\n",
    "file_path = './data.xlsx'\n",
    "output_folder = './matrices_por_dia'\n",
    "\n",
    "df = pd.read_excel(file_path, sheet_name='Hoja1', skiprows=2)\n",
    "\n",
    "df.columns = ['Index', 'Fecha', 'Nro.Estacion', 'Estacion'] + [f\"{i:02}\" for i in range(24)] + ['Total']\n",
    "df = df[['Fecha', 'Nro.Estacion'] + [f\"{i:02}\" for i in range(24)]]\n",
    "\n",
    "df['Fecha'] = pd.to_datetime(df['Fecha'], errors='coerce')\n",
    "df = df.dropna(subset=['Fecha', 'Nro.Estacion'])\n",
    "\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "for date, group in df.groupby(df['Fecha'].dt.date):\n",
    "    matrix = group.set_index('Nro.Estacion')[[f\"{i:02}\" for i in range(24)]].T\n",
    "    matrix = matrix.astype(int)  # Convertir a valores enteros\n",
    "    file_path = os.path.join(output_folder, f\"matriz_{date}.csv\")\n",
    "    matrix.to_csv(file_path)\n",
    "\n",
    "output_folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrices normalizadas creadas en la carpeta: ./matrices_normalizadas\n",
      "Scaler guardado en: ./scaler.pkl\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import joblib  \n",
    "\n",
    "input_folder = './matrices_por_dia'\n",
    "output_folder_normalized = './matrices_normalizadas'\n",
    "\n",
    "os.makedirs(output_folder_normalized, exist_ok=True)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "all_data = []\n",
    "metadata = []  \n",
    "\n",
    "file_names = [f for f in os.listdir(input_folder) if f.endswith('.csv')]\n",
    "for file_name in file_names:\n",
    "    file_path = os.path.join(input_folder, file_name)\n",
    "    df = pd.read_csv(file_path, index_col=0) \n",
    "    all_data.append(df.values)  \n",
    "    metadata.append((df.index, df.columns))  \n",
    "\n",
    "all_data_combined = pd.concat([pd.DataFrame(data) for data in all_data]).values\n",
    "\n",
    "scaler.fit(all_data_combined)\n",
    "normalized_data_combined = scaler.transform(all_data_combined)\n",
    "\n",
    "scaler_path = \"./scaler.pkl\"\n",
    "joblib.dump(scaler, scaler_path)\n",
    "\n",
    "start_idx = 0\n",
    "for file_name, (original_data, (index, columns)) in zip(file_names, zip(all_data, metadata)):\n",
    "    rows = original_data.shape[0]\n",
    "    normalized_data = normalized_data_combined[start_idx:start_idx + rows]\n",
    "    start_idx += rows\n",
    "\n",
    "    normalized_df = pd.DataFrame(normalized_data, index=index, columns=columns)\n",
    "    \n",
    "    output_file_path = os.path.join(output_folder_normalized, file_name)\n",
    "    normalized_df.to_csv(output_file_path)\n",
    "\n",
    "print(\"Matrices normalizadas creadas en la carpeta:\", output_folder_normalized)\n",
    "print(\"Scaler guardado en:\", scaler_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heatmaps generados con etiquetas en la carpeta: ./heatmaps\n",
      "Heatmaps generados sin etiquetas en la carpeta: ./heatmaps_no_labels\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "input_folder = './matrices_normalizadas'\n",
    "output_folder_heatmaps = './heatmaps'\n",
    "output_folder_heatmaps_no_labels = './heatmaps_no_labels'\n",
    "\n",
    "os.makedirs(output_folder_heatmaps, exist_ok=True)\n",
    "os.makedirs(output_folder_heatmaps_no_labels, exist_ok=True)\n",
    "\n",
    "file_names = [f for f in os.listdir(input_folder) if f.endswith('.csv')]\n",
    "\n",
    "for file_name in file_names:\n",
    "    file_path = os.path.join(input_folder, file_name)\n",
    "    df = pd.read_csv(file_path, index_col=0)\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(df, aspect='auto', cmap='viridis')  # Cambiar paleta si se desea\n",
    "    plt.colorbar(label='Escala Normalizada')\n",
    "    plt.title(f\"Heatmap: {file_name}\")\n",
    "    plt.xlabel('Estaciones')\n",
    "    plt.ylabel('Periodos de Tiempo')\n",
    "    output_path = os.path.join(output_folder_heatmaps, file_name.replace('.csv', '.png'))\n",
    "    plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(df, aspect='auto', cmap='viridis')  # Cambiar paleta si se desea\n",
    "    plt.axis('off')  # Desactiva las etiquetas de ejes y la barra de colores\n",
    "    output_path_no_labels = os.path.join(output_folder_heatmaps_no_labels, file_name.replace('.csv', '.png'))\n",
    "    plt.savefig(output_path_no_labels, dpi=300, bbox_inches='tight', pad_inches=0)  # Elimina bordes blancos\n",
    "    plt.close()\n",
    "\n",
    "print(\"Heatmaps generados con etiquetas en la carpeta:\", output_folder_heatmaps)\n",
    "print(\"Heatmaps generados sin etiquetas en la carpeta:\", output_folder_heatmaps_no_labels)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
